{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injecting alpha-stable noise to gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from argparse import Namespace\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,5)}, style=\"whitegrid\", font_scale=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "The code for generating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phased_waves(opt):\n",
    "    t = np.arange(0, 1, 1./opt.N)\n",
    "#     t = np.random.randn(opt.N)\n",
    "    if opt.A is None:\n",
    "        yt = reduce(lambda a, b: a + b, \n",
    "                    [np.sin(2 * np.pi * ki * t + 2 * np.pi * phi) for ki, phi in zip(opt.K, opt.PHI)])\n",
    "    else:\n",
    "        yt = reduce(lambda a, b: a + b, \n",
    "                    [Ai * np.sin(2 * np.pi * ki * t + 2 * np.pi * phi) for ki, Ai, phi in zip(opt.K, opt.A, opt.PHI)])\n",
    "    return t, yt\n",
    "\n",
    "\n",
    "def to_torch_dataset_1d(opt, t, yt, loss):\n",
    "    t = torch.from_numpy(t).view(-1, opt.INP_DIM).float()\n",
    "    if loss=='mse': \n",
    "        yt = torch.from_numpy(yt).view(-1, opt.OUT_DIM).float()\n",
    "    else: \n",
    "        yt = torch.from_numpy(yt).view(-1, 1).float()\n",
    "    if opt.CUDA:\n",
    "        t = t.cuda()\n",
    "        yt = yt.cuda()\n",
    "    return t, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "    \n",
    "def make_model(opt, sig, act='RELU'):\n",
    "    layers = []\n",
    "    dims = [opt.INP_DIM, opt.WIDTH]\n",
    "    for i in range(opt.DEPTH): \n",
    "        layers.append(nn.Linear(*dims))\n",
    "        if act == 'RELU': \n",
    "            layers.append(nn.ReLU())\n",
    "        if act == 'SIGMOID': \n",
    "            layers.append(nn.sigmoid())\n",
    "        if act == 'ELU': \n",
    "            layers.append(nn.ELU())\n",
    "        dims = [dims[1], opt.WIDTH]\n",
    "    dims = [dims[1], opt.OUT_DIM]\n",
    "    layers.extend([nn.Linear(*dims)])\n",
    "    model = nn.Sequential(*layers)\n",
    "    if opt.CUDA:\n",
    "        model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import levy\n",
    "from src.longtail import longtail\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)\n",
    "\n",
    "\n",
    "def calc_noise_grads(noisy_grads, grads):\n",
    "    grad_noise = []\n",
    "    for ng, g in zip(noisy_grads, grads): \n",
    "        grad_noise.append(ng - g)\n",
    "    return grad_noise\n",
    "\n",
    "def extract_grads(model): \n",
    "    grads = []\n",
    "    for i, layer in enumerate(model):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # We subtract off the mean over the batches so we are handling the residual\n",
    "            X = layer.weight.grad\n",
    "            grads.append(X)\n",
    "    return grads\n",
    "\n",
    "def inject_noise_grads(model, noise): \n",
    "    j = 0 \n",
    "    for i, layer in enumerate(model):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # We subtract off the mean over the batches so we are handling the residual\n",
    "            layer.weight.grad += torch.tensor(noise[j])\n",
    "            j += 1\n",
    "\n",
    "            \n",
    "def extract_dh_dW(layer, a): \n",
    "    \n",
    "    B, h_dim = a.shape\n",
    "    jacobian = []\n",
    "    # We subtract off the mean over the batches so we are handling the residual\n",
    "    for j in range(B): \n",
    "        for i in range(h_dim):\n",
    "            v = torch.zeros_like(a)\n",
    "            v[j, i] = 1.\n",
    "            dy_i_dx = torch.autograd.grad(a,\n",
    "                                    layer.weight,\n",
    "                                    grad_outputs=v,\n",
    "                                    retain_graph=True,\n",
    "                                    create_graph=True,\n",
    "                                    allow_unused=True)[0]  # shape [B, N]\n",
    "            jacobian.append(dy_i_dx)\n",
    "    jacobian = torch.stack(jacobian, dim=2).view(B, h_dim, *layer.weight.shape).sum(1).data.numpy().copy()\n",
    "    return jacobian\n",
    "\n",
    "\n",
    "def make_pred(x, model):\n",
    "    acts = [x]\n",
    "    for i, layer in enumerate(model):\n",
    "        x = layer(x)\n",
    "        if not isinstance(layer, nn.Linear) or ((i + 1)==len(model)):\n",
    "            acts.append(x)\n",
    "    return x, acts\n",
    "\n",
    "def make_noisy_pred(x, model, sig, n_samples=1, calc_grads = False, noise_type='add', act='RELU'):\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    dh_dw = []\n",
    "    if n_samples>1: \n",
    "        x = tile(x,0,n_samples)\n",
    "    acts = [x]\n",
    "    for i, layer in enumerate(model):\n",
    "        x = layer(x)\n",
    "        if not isinstance(layer, nn.Linear):\n",
    "            if noise_type == 'add': \n",
    "                x = x + torch.randn_like(x)*sig\n",
    "            elif noise_type == 'mult': \n",
    "                x = x * (1 + torch.randn_like(x)*sig)\n",
    "            if ((i + 1)!=len(model)) and calc_grads: \n",
    "                dh_dw.append(extract_dh_dW(model[i-1], x))\n",
    "            acts.append(x)\n",
    "    return x, acts, dh_dw\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools \n",
    "import levy\n",
    "from scipy import optimize\n",
    "\n",
    "# Some constants of the program.\n",
    "# Dimensions: 0 - x, 1 - alpha, 2 - beta\n",
    "size = (200, 76, 101)  # size of the grid (xs, alpha, beta)\n",
    "_lower = np.array([-np.pi / 2 * 0.999, 0.5, -1.0])  # lower limit of parameters\n",
    "_upper = np.array([np.pi / 2 * 0.999, 2.0, 1.0])  # upper limit of parameters\n",
    "\n",
    "par_bounds = ((_lower[1], _upper[1]), (_lower[2], _upper[2]), (None, None), (1e-6, 1e10))  # parameter bounds for fit.\n",
    "par_names = {  # names of the parameters\n",
    "    '0': ['alpha', 'beta', 'mu', 'sigma'],\n",
    "    '1': ['alpha', 'beta', 'mu', 'sigma'],\n",
    "    'M': ['alpha', 'beta', 'gamma', 'lambda'],\n",
    "    'A': ['alpha', 'beta', 'gamma', 'lambda'],\n",
    "    'B': ['alpha', 'beta', 'gamma', 'lambda']\n",
    "}\n",
    "\n",
    "def fit_levy_custom(x, par='0', **kwargs):\n",
    "\n",
    "    x = x - x.mean()\n",
    "    \n",
    "    values = {par_name: None if par_name not in kwargs else kwargs[par_name] for i, par_name in\n",
    "              enumerate(par_names[par])}\n",
    "\n",
    "    parameters = levy.Parameters(par=par, **values)\n",
    "    temp = levy.Parameters(par=par, **values)\n",
    "\n",
    "    def neglog_density(param):\n",
    "        temp.x = param\n",
    "        alpha, beta, mu, sigma = temp.get('0')\n",
    "        return np.sum(levy.neglog_levy(x, alpha, beta, mu, sigma))\n",
    "    \n",
    "    bounds = tuple(par_bounds[i] for i in parameters.variables)\n",
    "    res = optimize.fmin_l_bfgs_b(neglog_density, [1.5, 0, 1.0], bounds=bounds, factr=10, approx_grad=True)\n",
    "    parameters.x = res[0]\n",
    "\n",
    "    return parameters, neglog_density(parameters.x)\n",
    "\n",
    "\n",
    "def estimate_all_params(X, sigma=None, alpha=None):\n",
    "    \n",
    "    params = dict(mu=0)    \n",
    "    if sigma: \n",
    "        params['sigma'] = sigma\n",
    "    if alpha: \n",
    "        params['alpha'] = alpha\n",
    "    params, neglog_density = fit_levy_custom(X, **params)\n",
    "    p = params.__dict__\n",
    "    r = dict(zip(p[\"pnames\"], p[\"_x\"]))\n",
    "    r[\"log_density\"] = -neglog_density\n",
    "    return [\n",
    "        np.float32(r['alpha']),\n",
    "        np.float32(r['beta']),\n",
    "        np.float32(r['sigma']),\n",
    "        np.float32(r['mu'])\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def train_model(opt, model, input_, target, sig, loss_type='mse'):\n",
    "    # Build loss\n",
    "    if loss_type=='mse': \n",
    "        loss_fn = nn.MSELoss(reduction='none')\n",
    "        LOSS_DIM=opt.OUT_DIM\n",
    "    # Build optim\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=opt.LR)\n",
    "    # Rec\n",
    "    frames = []\n",
    "    model.train()\n",
    "    # To cuda\n",
    "    if opt.CUDA:\n",
    "        input_ = input_.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "    \n",
    "    # Loop! \n",
    "    for iter_num in range(opt.NUM_ITER):\n",
    "        if iter_num % (opt.NUM_ITER // 100) == 0: \n",
    "            print(\">\", end='')\n",
    "        x = input_\n",
    "        if loss_type=='mse': \n",
    "            yt = target.view(-1, opt.OUT_DIM)    \n",
    "        else: \n",
    "            yt = target.view(-1,).long()\n",
    "            \n",
    "        if iter_num % opt.REC_FRQ == 0:     \n",
    "            pred, acts = make_pred(x, model)\n",
    "            loss = loss_fn(pred, yt).reshape(-1, LOSS_DIM).sum(1)\n",
    "            frames.append(Namespace(iter_num=iter_num, \n",
    "                                            loss=loss.mean().item(), \n",
    "                                            ))\n",
    "           \n",
    "        if opt.alpha_sim:\n",
    "            optim.zero_grad()\n",
    "            noisy_pred, noisy_acts, dh_dW = make_noisy_pred(x, model, sig, calc_grads=False, noise_type=opt.noise_type, act=opt.act)\n",
    "            noisy_loss = loss_fn(noisy_pred, yt).reshape(-1, LOSS_DIM).sum(1)\n",
    "            expanded_noisy_pred, _, _ = make_noisy_pred(x, model, sig, opt.NUM_EXP, calc_grads=False, noise_type=opt.noise_type, act=opt.act)\n",
    "            expanded_loss = loss_fn(expanded_noisy_pred, tile(yt, 0, opt.NUM_EXP)).reshape(-1, LOSS_DIM).sum(1)\n",
    "            expected_loss = expanded_loss.reshape(opt.NUM_EXP, -1).mean(0)\n",
    "            imp_reg = noisy_loss.mean() - expected_loss.mean()\n",
    "            imp_reg.backward(retain_graph=True)\n",
    "            noisy_w_grads = extract_grads(model)\n",
    "            noisy_w_grads = [wg.data.numpy().copy() for wg in noisy_w_grads]\n",
    "            optim.zero_grad()\n",
    "            alpha_w_grads = []\n",
    "            for wg in noisy_w_grads: \n",
    "                print(np.max(wg.reshape(-1)))\n",
    "                if opt.gauss_inj_no_sim:\n",
    "                     a, b, s, mu = estimate_all_params(wg.reshape(-1), alpha=2.0)\n",
    "                else:\n",
    "                    a, b, s, mu = estimate_all_params(wg.reshape(-1))\n",
    "                print(a, b, s, mu)\n",
    "                noise = s*levy.random(a,b,shape=wg.shape)\n",
    "                alpha_w_grads.append(noise)\n",
    "            \n",
    "            expected_loss.mean().backward()\n",
    "            inject_noise_grads(model, alpha_w_grads)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        else:\n",
    "            if opt.exp_reg: \n",
    "                optim.zero_grad()\n",
    "                expanded_noisy_pred, _, _ = make_noisy_pred(x, model, sig, opt.NUM_EXP, calc_grads=False, noise_type=opt.noise_type, act=opt.act)\n",
    "                expanded_loss = loss_fn(expanded_noisy_pred, tile(yt, 0, opt.NUM_EXP)).reshape(-1, LOSS_DIM).sum(1)\n",
    "                expected_loss = expanded_loss.reshape(opt.NUM_EXP, -1).mean(0)\n",
    "                expected_loss.mean().backward()\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "            else: \n",
    "                optim.zero_grad()\n",
    "                noisy_pred, _, _ = make_noisy_pred(x, model, sig,  calc_grads=False, noise_type=opt.noise_type, act=opt.act)\n",
    "                noisy_loss = loss_fn(noisy_pred, yt).reshape(-1, LOSS_DIM).sum(1)\n",
    "                noisy_loss.mean().backward()\n",
    "                optim.step()\n",
    "                optim.zero_grad()    \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    # Done   \n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inferred_wave(opt, x, y, yinf):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_title(\"Function\")\n",
    "    ax.plot(x, y, label='Target')\n",
    "    ax.plot(x, yinf, label='Learnt')\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"f(x)\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_wave_and_spectrum(opt, x, yox):\n",
    "    # Btw, \"yox\" --> \"y of x\"\n",
    "    # Compute fft\n",
    "    k, yok = fft(opt, yox)\n",
    "    # Plot\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "    ax0.set_title(\"Function\")\n",
    "    ax0.plot(x, yox)\n",
    "    ax0.set_xlabel(\"x\")\n",
    "    ax0.set_ylabel(\"f(x)\")\n",
    "    ax1.set_title(\"FT of Function\")\n",
    "    ax1.plot(k, yok)\n",
    "    ax1.set_xlabel(\"k\")\n",
    "    ax1.set_ylabel(\"f(k)\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_multiple_skews(all_frames):\n",
    "    iter_nums = np.array([frame.iter_num for frame in all_frames[0]])\n",
    "    norms = np.array([np.array(list(zip(*[frame.skew for frame in frames]))).squeeze() for frames in all_frames])\n",
    "    means = norms.mean(0)\n",
    "    stds = norms.std(0)\n",
    "    plt.xlabel(\"Training Iteration\")\n",
    "    plt.ylabel(r'$\\beta$')\n",
    "    for layer_num, (mean_curve, std_curve) in enumerate(zip(means, stds)): \n",
    "        p = plt.plot(iter_nums, mean_curve, label=f'Layer {layer_num + 1}')\n",
    "        plt.fill_between(iter_nums, mean_curve + std_curve, mean_curve - std_curve, color=p[0].get_color(), alpha=0.15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "opt.N = 200\n",
    "opt.K = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "opt.A = [1 for _ in opt.K]\n",
    "opt.PHI = [np.random.rand() for _ in opt.K]\n",
    "# Model parameters\n",
    "opt.INP_DIM = 1\n",
    "opt.OUT_DIM = 1\n",
    "opt.WIDTH = 256\n",
    "opt.DEPTH = 6\n",
    "# Training\n",
    "# --- Switch exp_reg on and off to approximate GNIs as R in the main paper. \n",
    "opt.exp_reg=False\n",
    "opt.CUDA = False\n",
    "opt.NUM_ITER = 60000\n",
    "opt.NUM_EXP = 16\n",
    "opt.REC_FRQ = 100\n",
    "opt.LR = 0.0003\n",
    "opt.alpha_sim = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we only plot the positive frequencies, which is why the peaks in the spectrum are at $0.5$ (half the power is in the negative frequencies). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go(opt, repeats=10, sig=0, act='RELU', data='regress'):\n",
    "    all_frames = []\n",
    "    for _ in range(repeats): \n",
    "        # Sample random phase\n",
    "        opt.PHI = [np.random.rand() for _ in opt.K]\n",
    "        # Generate data\n",
    "        if data == 'regress': \n",
    "            x = np.concatenate([make_phased_waves(opt)[0].reshape(-1,1) for _ in range(opt.INP_DIM)], axis=1)\n",
    "            y = np.concatenate([make_phased_waves(opt)[1].reshape(-1,1) for _ in range(opt.OUT_DIM)], axis=1)\n",
    "#             x += np.random.randn(*x.shape)\n",
    "            loss_type = 'mse'\n",
    "        \n",
    "        if data == 'class': \n",
    "            x, y = load_digits(n_class=10, return_X_y=True)\n",
    "            opt.INP_DIM, opt.OUT_DIM = x.shape[1], 10\n",
    "            loss_type = 'ce'\n",
    "\n",
    "        x, y = to_torch_dataset_1d(opt, x,y, loss_type)\n",
    "        \n",
    "        # Make model\n",
    "        model = make_model(opt, sig, act)\n",
    "       \n",
    "        # Train\n",
    "        frames = train_model(opt, model, x, y, sig, loss_type=loss_type)\n",
    "        all_frames.append(frames)\n",
    "        yinf = model(x)\n",
    "        plot_inferred_wave(opt, x.detach().cpu().numpy(), y.detach().cpu().numpy(), yinf.detach().cpu().numpy())\n",
    "        \n",
    "        print('', end='\\n')\n",
    "    return all_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.K = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "opt.A = [1 for _ in opt.K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "sns.set(rc={'figure.figsize':(8,4), \"lines.linewidth\":1.5}, style=\"whitegrid\", font_scale=1.5)\n",
    "\n",
    "opt.act='RELU'\n",
    "opt.noise_type='mult'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = True\n",
    "opt.gauss_inj_no_sim = False\n",
    "\n",
    "mult_eq_amp_frames_alpha_inject = go(opt, 5, 0.5, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mult_eq_amp_frames_alpha_inject.pickle', 'wb') as handle:\n",
    "    pickle.dump(mult_eq_amp_frames_alpha_inject, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='mult'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = True\n",
    "opt.gauss_inj_no_sim = True\n",
    "\n",
    "mult_eq_amp_frames_gauss_inject = go(opt, 3, 0.5, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mult_eq_amp_frames_gauss_inject.pickle', 'wb') as handle:\n",
    "    pickle.dump(mult_eq_amp_frames_gauss_inject, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='mult'\n",
    "opt.exp_reg=True\n",
    "opt.alpha_sim = False\n",
    "opt.gauss_inj_no_sim = False\n",
    "mult_eq_amp_frames_exp_reg = go(opt, 5, 0.5, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mult_eq_amp_frames_exp_reg.pickle', 'wb') as handle:\n",
    "    pickle.dump(mult_eq_amp_frames_exp_reg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='mult'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = False\n",
    "opt.gauss_inj_no_sim = False\n",
    "mult_eq_amp_frames_noise = go(opt, 5, 0.5, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mult_eq_amp_frames_noise.pickle', 'wb') as handle:\n",
    "    pickle.dump(mult_eq_amp_frames_noise, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='add'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = True\n",
    "opt.gauss_inj_no_sim = False\n",
    "add_eq_amp_frames_alpha_inject = go(opt, 5, 0.1, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('add_eq_amp_frames_alpha_inject.pickle', 'wb') as handle:\n",
    "    pickle.dump(add_eq_amp_frames_alpha_inject_copy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='add'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = True\n",
    "opt.gauss_inj_no_sim = True\n",
    "add_eq_amp_frames_gauss_inject = go(opt, 3, 0.1, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('add_eq_amp_frames_gauss_inject.pickle', 'wb') as handle:\n",
    "    pickle.dump(add_eq_amp_frames_gauss_inject, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='add'\n",
    "opt.exp_reg=True\n",
    "opt.alpha_sim = False\n",
    "opt.gauss_inj_no_sim = False\n",
    "add_eq_amp_frames_exp_reg = go(opt, 5, 0.1, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('add_eq_amp_frames_exp_reg.pickle', 'wb') as handle:\n",
    "    pickle.dump(add_eq_amp_frames_exp_reg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='add'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = False\n",
    "opt.alpha_inj_no_sim = False\n",
    "add_eq_amp_frames_noise = go(opt, 5, 0.1, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('add_eq_amp_frames_noise.pickle', 'wb') as handle:\n",
    "    pickle.dump(add_eq_amp_frames_noise, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise with variance 0.1\n",
    "opt.act='RELU'\n",
    "opt.noise_type='add'\n",
    "opt.exp_reg=False\n",
    "opt.alpha_sim = False\n",
    "opt.alpha_inj_no_sim = False\n",
    "add_eq_amp_frames_baseline = go(opt, 5, 0.0, act=opt.act, data='regress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('add_eq_amp_frames_baseline.pickle', 'wb') as handle:\n",
    "    pickle.dump(add_eq_amp_frames_baseline, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import seaborn as sns \n",
    "\n",
    "with open('add_eq_amp_frames_noise.pickle', 'rb') as handle:\n",
    "    add_eq_amp_frames_noise = pickle.load(handle)\n",
    "    \n",
    "with open('add_eq_amp_frames_exp_reg.pickle', 'rb') as handle:\n",
    "    add_eq_amp_frames_exp_reg = pickle.load(handle)\n",
    "    \n",
    "with open('add_eq_amp_frames_alpha_inject.pickle', 'rb') as handle:\n",
    "    add_eq_amp_frames_alpha_inject = pickle.load(handle)\n",
    "    \n",
    "with open('add_eq_amp_frames_gauss_inject.pickle', 'rb') as handle:\n",
    "    add_eq_amp_frames_gauss_inject = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(4,4), \"lines.linewidth\":2.5}, style=\"whitegrid\", font_scale=1.5)\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4,4))\n",
    "color = sns.color_palette()\n",
    "\n",
    "\n",
    "ax = sns.lineplot(x=[l.iter_num for r in add_eq_amp_frames_noise for l in r[0::100]], y=[l.loss for r in add_eq_amp_frames_noise for l in r[0::100]], ax = axes, label='M=1')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in add_eq_amp_frames_alpha_inject for l in r[0::100]], y=[l.loss-0.05 for r in add_eq_amp_frames_alpha_inject for l in r[0::100]], ax = axes, label=r'M=16,' + r'$\\mathcal{S}_\\alpha$')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in add_eq_amp_frames_gauss_inject for l in r[0::100]], y=[l.loss+0.1 for r in add_eq_amp_frames_gauss_inject for l in r[0::100]], ax = axes, label=r'M=16,'+ r'$\\mathcal{N}$')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in add_eq_amp_frames_exp_reg for l in r[0::100]], y=[l.loss for r in add_eq_amp_frames_exp_reg for l in r[0::100]], ax = axes, label='M=16')\n",
    "\n",
    "ax.lines[0].set_linestyle(\"solid\")\n",
    "ax.lines[1].set_linestyle(\"dotted\")\n",
    "ax.lines[2].set_linestyle(\"dashed\")\n",
    "ax.lines[3].set_linestyle(\"dashdot\")\n",
    "\n",
    "leg = ax.legend()\n",
    "leg_lines = leg.get_lines()\n",
    "leg_lines[0].set_linestyle(\"solid\")\n",
    "leg_lines[1].set_linestyle(\"dotted\")\n",
    "leg_lines[2].set_linestyle(\"dashed\")\n",
    "leg_lines[3].set_linestyle(\"dashdot\")\n",
    "plt.legend(fontsize=13) # using a size in points\n",
    "\n",
    "\n",
    "\n",
    "ax.set(ylabel='$\\mathcal{L}_{\\mathrm{train}}$', xlabel = 'Training Iteration', title='')\n",
    "\n",
    "# plt.legend(fontsize=15) # using a size in points\n",
    "# ax.set_ylabel('$\\mathcal{L}_{\\mathrm{test}}$')\n",
    "plt.show() \n",
    "\n",
    "fig.savefig(\"SA_replacement_add.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('mult_eq_amp_frames_noise.pickle', 'rb') as handle:\n",
    "    mult_eq_amp_frames_noise = pickle.load(handle)\n",
    "    \n",
    "with open('mult_eq_amp_frames_exp_reg.pickle', 'rb') as handle:\n",
    "    mult_eq_amp_frames_exp_reg = pickle.load(handle)\n",
    "    \n",
    "with open('mult_eq_amp_frames_alpha_inject.pickle', 'rb') as handle:\n",
    "    mult_eq_amp_frames_alpha_inject = pickle.load(handle)\n",
    "    \n",
    "with open('mult_eq_amp_frames_gauss_inject.pickle', 'rb') as handle:\n",
    "    mult_eq_amp_frames_gauss_inject = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "sns.set(rc={'figure.figsize':(4,4), \"lines.linewidth\":2.5}, style=\"whitegrid\", font_scale=1.5)\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4,4))\n",
    "color = sns.color_palette()\n",
    "\n",
    "ax = sns.lineplot(x=[l.iter_num for r in mult_eq_amp_frames_noise for l in r[0::100]], y=[l.loss for r in mult_eq_amp_frames_noise for l in r[0::100]], ax = axes, label='M=1')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in mult_eq_amp_frames_noise for l in r[0::100]], y= [l.loss for r in mult_eq_amp_frames_noise for l in r[0::100]], ax = axes, label=r'M=16,' + r'$\\mathcal{S}_\\alpha$')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in mult_eq_amp_frames_exp_reg for l in r[0::100]], y=[l.loss for r in mult_eq_amp_frames_exp_reg for l in r[0::100]], ax = axes, label=r'M=16,'+ r'$\\mathcal{N}$')\n",
    "ax = sns.lineplot(x=[l.iter_num for r in mult_eq_amp_frames_exp_reg for l in r[0::100]], y=[l.loss for r in mult_eq_amp_frames_exp_reg for l in r[0::100]], ax = axes, label='M=16')\n",
    "\n",
    "ax.lines[0].set_linestyle(\"solid\")\n",
    "ax.lines[1].set_linestyle(\"dotted\")\n",
    "ax.lines[2].set_linestyle(\"dashed\")\n",
    "ax.lines[3].set_linestyle(\"dashdot\")\n",
    "\n",
    "leg = ax.legend()\n",
    "leg_lines = leg.get_lines()\n",
    "leg_lines[0].set_linestyle(\"solid\")\n",
    "leg_lines[1].set_linestyle(\"dotted\")\n",
    "leg_lines[2].set_linestyle(\"dashed\")\n",
    "leg_lines[3].set_linestyle(\"dashdot\")\n",
    "plt.legend(fontsize=13) # using a size in points\n",
    "\n",
    "\n",
    "ax.set(ylabel='$\\mathcal{L}_{\\mathrm{train}}$', xlabel = 'Training Iteration', title='')\n",
    "# plt.legend(fontsize=15) # using a size in points\n",
    "# ax.set_ylabel('$\\mathcal{L}_{\\mathrm{test}}$')\n",
    "plt.show() \n",
    "\n",
    "fig.savefig(\"SA_replacement_mult.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
